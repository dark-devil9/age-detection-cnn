{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a4227c3",
      "metadata": {
        "id": "1a4227c3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f76e48",
      "metadata": {
        "id": "93f76e48"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path):\n",
        "    images=[]\n",
        "    ages=[]\n",
        "    for filename in os.listdir(data_path):\n",
        "        try:\n",
        "            age=int(filename.split(\"_\")[0])\n",
        "            img=Image.open(os.path.join(data_path, filename)).resize((100, 100))\n",
        "            img=np.array(img)/255.0\n",
        "            if img.shape==(100,100,3):\n",
        "                images.append(img)\n",
        "                ages.append(age)\n",
        "\n",
        "        except:\n",
        "            continue\n",
        "    return np.array(images), np.array(ages)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6vJuNVo0U-e",
        "outputId": "cac83424-5bbe-4631-e398-dd4a8942fff3"
      },
      "id": "T6vJuNVo0U-e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Age Detection/Age Detection/UTKFace.zip'  # Make sure this matches the uploaded file name\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/Age Detection/Age Detection/UTKFace')  # Extract into a folder named \"UTKFace\"\n"
      ],
      "metadata": {
        "id": "Wrwc9AstXPPz"
      },
      "id": "Wrwc9AstXPPz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())           # Shows your current working directory\n",
        "print(len(os.listdir(\"drive/MyDrive/Age Detection/Age Detection/UTKFace/UTKFace\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZnoleLKy-nU",
        "outputId": "12525b14-ba72-4e80-aacc-28aab5441130"
      },
      "id": "BZnoleLKy-nU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "21807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class UTKFaceDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_paths, labels, batch_size=32, img_size=(100, 100), shuffle=True):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_paths = [self.image_paths[i] for i in batch_indexes]\n",
        "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
        "\n",
        "        batch_images = []\n",
        "        for path in batch_paths:\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.resize(img, self.img_size)\n",
        "            img = img / 255.0\n",
        "            batch_images.append(img)\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "t0mVQyZ7dpb0"
      },
      "id": "t0mVQyZ7dpb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "dataset_path = \"drive/MyDrive/Age Detection/Age Detection/UTKFace/UTKFace\"\n",
        "all_files = glob.glob(os.path.join(dataset_path, \"*.jpg\"))  # or .jpeg/.png if needed\n",
        "\n",
        "# Parse age from filename\n",
        "all_ages = [int(os.path.basename(f).split(\"_\")[0]) for f in all_files]\n",
        "\n",
        "# Split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_paths, val_paths, train_ages, val_ages = train_test_split(all_files, all_ages, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "Y472smNldpYU"
      },
      "id": "Y472smNldpYU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = UTKFaceDataGenerator(train_paths, train_ages, batch_size=32)\n",
        "val_gen = UTKFaceDataGenerator(val_paths, val_ages, batch_size=32)\n"
      ],
      "metadata": {
        "id": "B2r6yYc6dwni"
      },
      "id": "B2r6yYc6dwni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae8f6f81",
      "metadata": {
        "id": "ae8f6f81"
      },
      "outputs": [],
      "source": [
        "images,ages=load_data('drive/MyDrive/Age Detection/Age Detection/UTKFace/UTKFace')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2353855e",
      "metadata": {
        "id": "2353855e"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32,(3,3),activation='relu',input_shape=(100,100,3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Conv2D(64,(3,3),activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Conv2D(128,(3,3),activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "\n",
        "\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef049a42",
      "metadata": {
        "id": "ef049a42"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    # X_train,X_test,Y_train,Y_test=train_test_split(images,ages,test_size=0.2)\n",
        "    model=build_model()\n",
        "\n",
        "    print(type(model))\n",
        "\n",
        "\n",
        "    model.fit(train_gen, validation_data=val_gen, epochs=60)\n",
        "    model.save('/content/drive/MyDrive/new_age_model.h5')\n",
        "    print(\"Model saved to age_model.h5\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad5dad7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ad5dad7",
        "outputId": "e3ce4f12-6908-43b5-bc24-d15a0c020059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.src.models.sequential.Sequential'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m  6/545\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16:56\u001b[0m 9s/step - loss: 821.6451 - mae: 24.7120"
          ]
        }
      ],
      "source": [
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bdbe02",
      "metadata": {
        "id": "01bdbe02",
        "outputId": "1f842918-01a1-40ba-c5bc-dd85e48f931a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e479a95e818a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mlive_age_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-e479a95e818a>\u001b[0m in \u001b[0;36mlive_age_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ],
      "source": [
        "def range_age(age):\n",
        "\n",
        "    if 0 <= age <= 2:\n",
        "        return \"0-2\"\n",
        "    elif 3 <= age <= 9:\n",
        "        return \"3-9\"\n",
        "    elif 10 <= age <= 20:\n",
        "        return \"10-20\"\n",
        "    elif 21 <= age <= 27:\n",
        "        return \"21-27\"\n",
        "    elif 28 <= age <= 45:\n",
        "        return \"28-45\"\n",
        "    elif 46 <= age <= 65:\n",
        "        return \"45-65\"\n",
        "    else:\n",
        "        return \"65+\"\n",
        "\n",
        "\n",
        "\n",
        "def live_age_prediction():\n",
        "    if not os.path.exists(\"age_model.h5\"):\n",
        "        print(\"⚠️ Model not found. Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    model = tf.keras.models.load_model(\"age_model.h5\")\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "            face_resized = cv2.resize(face, (100, 100)) / 255.0\n",
        "            face_input = np.expand_dims(face_resized, axis=0)\n",
        "\n",
        "            age_pred = model.predict(face_input, verbose=0)[0][0]\n",
        "            range=range_age(age_pred)\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f'Age: {range}', (x, y-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"Live Age Detection\", frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "live_age_prediction()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}